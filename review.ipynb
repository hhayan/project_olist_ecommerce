{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6e1998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\mumu1\\desktop\\project_movie_data\\venv\\lib\\site-packages (3.9.2)\n",
      "Requirement already satisfied: wordcloud in c:\\users\\mumu1\\desktop\\project_movie_data\\venv\\lib\\site-packages (1.9.4)\n",
      "Collecting leia-br\n",
      "  Downloading leia_br-0.0.1-py2.py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: xgboost in c:\\users\\mumu1\\desktop\\project_movie_data\\venv\\lib\\site-packages (3.1.1)\n",
      "Requirement already satisfied: lightgbm in c:\\users\\mumu1\\desktop\\project_movie_data\\venv\\lib\\site-packages (4.6.0)\n",
      "Requirement already satisfied: catboost in c:\\users\\mumu1\\desktop\\project_movie_data\\venv\\lib\\site-packages (1.2.8)\n",
      "Requirement already satisfied: click in c:\\users\\mumu1\\desktop\\project_movie_data\\venv\\lib\\site-packages (from nltk) (8.3.0)\n",
      "Requirement already satisfied: joblib in c:\\users\\mumu1\\desktop\\project_movie_data\\venv\\lib\\site-packages (from nltk) (1.5.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\mumu1\\desktop\\project_movie_data\\venv\\lib\\site-packages (from nltk) (2025.10.23)\n",
      "Requirement already satisfied: tqdm in c:\\users\\mumu1\\desktop\\project_movie_data\\venv\\lib\\site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: numpy>=1.6.1 in c:\\users\\mumu1\\desktop\\project_movie_data\\venv\\lib\\site-packages (from wordcloud) (2.3.2)\n",
      "Requirement already satisfied: pillow in c:\\users\\mumu1\\desktop\\project_movie_data\\venv\\lib\\site-packages (from wordcloud) (11.3.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\mumu1\\desktop\\project_movie_data\\venv\\lib\\site-packages (from wordcloud) (3.10.5)\n",
      "Requirement already satisfied: requests in c:\\users\\mumu1\\desktop\\project_movie_data\\venv\\lib\\site-packages (from leia-br) (2.32.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\mumu1\\desktop\\project_movie_data\\venv\\lib\\site-packages (from xgboost) (1.16.1)\n",
      "Requirement already satisfied: graphviz in c:\\users\\mumu1\\desktop\\project_movie_data\\venv\\lib\\site-packages (from catboost) (0.21)\n",
      "Requirement already satisfied: pandas>=0.24 in c:\\users\\mumu1\\desktop\\project_movie_data\\venv\\lib\\site-packages (from catboost) (2.3.1)\n",
      "Requirement already satisfied: plotly in c:\\users\\mumu1\\desktop\\project_movie_data\\venv\\lib\\site-packages (from catboost) (6.3.1)\n",
      "Requirement already satisfied: six in c:\\users\\mumu1\\desktop\\project_movie_data\\venv\\lib\\site-packages (from catboost) (1.17.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\mumu1\\desktop\\project_movie_data\\venv\\lib\\site-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\mumu1\\desktop\\project_movie_data\\venv\\lib\\site-packages (from pandas>=0.24->catboost) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\mumu1\\desktop\\project_movie_data\\venv\\lib\\site-packages (from pandas>=0.24->catboost) (2025.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\mumu1\\desktop\\project_movie_data\\venv\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\mumu1\\desktop\\project_movie_data\\venv\\lib\\site-packages (from matplotlib->wordcloud) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\mumu1\\desktop\\project_movie_data\\venv\\lib\\site-packages (from matplotlib->wordcloud) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\mumu1\\desktop\\project_movie_data\\venv\\lib\\site-packages (from matplotlib->wordcloud) (4.59.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\mumu1\\desktop\\project_movie_data\\venv\\lib\\site-packages (from matplotlib->wordcloud) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\mumu1\\desktop\\project_movie_data\\venv\\lib\\site-packages (from matplotlib->wordcloud) (25.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\mumu1\\desktop\\project_movie_data\\venv\\lib\\site-packages (from matplotlib->wordcloud) (3.2.3)\n",
      "Requirement already satisfied: narwhals>=1.15.1 in c:\\users\\mumu1\\desktop\\project_movie_data\\venv\\lib\\site-packages (from plotly->catboost) (2.9.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\mumu1\\desktop\\project_movie_data\\venv\\lib\\site-packages (from requests->leia-br) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\mumu1\\desktop\\project_movie_data\\venv\\lib\\site-packages (from requests->leia-br) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\mumu1\\desktop\\project_movie_data\\venv\\lib\\site-packages (from requests->leia-br) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mumu1\\desktop\\project_movie_data\\venv\\lib\\site-packages (from requests->leia-br) (2025.8.3)\n",
      "Downloading leia_br-0.0.1-py2.py3-none-any.whl (130 kB)\n",
      "Installing collected packages: leia-br\n",
      "Successfully installed leia-br-0.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install nltk wordcloud xgboost lightgbm catboost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ebfbe1ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: leia-br 0.0.1\n",
      "Uninstalling leia-br-0.0.1:\n",
      "  Successfully uninstalled leia-br-0.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting leia-br\n",
      "  Using cached leia_br-0.0.1-py2.py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\mumu1\\desktop\\project_movie_data\\venv\\lib\\site-packages (from leia-br) (2.32.4)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\mumu1\\desktop\\project_movie_data\\venv\\lib\\site-packages (from requests->leia-br) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\mumu1\\desktop\\project_movie_data\\venv\\lib\\site-packages (from requests->leia-br) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\mumu1\\desktop\\project_movie_data\\venv\\lib\\site-packages (from requests->leia-br) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mumu1\\desktop\\project_movie_data\\venv\\lib\\site-packages (from requests->leia-br) (2025.8.3)\n",
      "Using cached leia_br-0.0.1-py2.py3-none-any.whl (130 kB)\n",
      "Installing collected packages: leia-br\n",
      "Successfully installed leia-br-0.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip uninstall leia-br -y\n",
    "%pip install leia-br"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "380f6cbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\mumu1\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\mumu1\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "plt.rcParams['font.family'] = 'Malgun Gothic'\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# Text Processing Libraries\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from wordcloud import WordCloud\n",
    "from collections import Counter\n",
    "from nltk import ngrams\n",
    "\n",
    "# Sentiment Analysis\n",
    "from LeIA import SentimentIntensityAnalyzer\n",
    "\n",
    "# Download required NLTK data\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Machine Learning Libraries\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder, label_binarize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import (\n",
    "    AdaBoostClassifier, GradientBoostingClassifier, RandomForestClassifier\n",
    ")\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# Evaluation Metrics\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score, classification_report, \n",
    "    confusion_matrix, roc_curve, roc_auc_score, ConfusionMatrixDisplay, auc\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3d5fa7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML\n",
    "HTML('''<style>\n",
    "div.output_area {\n",
    "    max-height: none !important;\n",
    "}\n",
    "</style>''')\n",
    "\n",
    "# 출력 제한 완전히 제거\n",
    "get_ipython().run_line_magic('config', \"InlineBackend.print_figure_kwargs = {'bbox_inches': None}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8fc3f9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from RFM import df_order_reviews, df_product_category_name_translation, df_products, merge_coi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e18dc3",
   "metadata": {},
   "source": [
    "# Merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f23ce7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) 전체 분석 review_comment_message, product_category_name, order_id\n",
    "# 2) 이탈고객 vs 잠재우수 고객\n",
    "\n",
    "df_reviews = df_order_reviews[['order_id', 'review_comment_message']]\n",
    "\n",
    "# merge_coi + df_products = NLP\n",
    "NLP = merge_coi.merge(\n",
    "    df_products[['product_id', 'product_category_name']],  \n",
    "    on='product_id',\n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "# NLP + df_reviews = NLP\n",
    "NLP = NLP.merge(\n",
    "    df_reviews[['order_id', 'review_comment_message']], \n",
    "    on='order_id',\n",
    "    how='inner'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2208fd3",
   "metadata": {},
   "source": [
    "# Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cf5976a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 33495 entries, 0 to 33494\n",
      "Data columns (total 3 columns):\n",
      " #   Column                  Non-Null Count  Dtype \n",
      "---  ------                  --------------  ----- \n",
      " 0   order_id                33495 non-null  object\n",
      " 1   review_comment_message  33495 non-null  object\n",
      " 2   product_category_name   33495 non-null  object\n",
      "dtypes: object(3)\n",
      "memory usage: 785.2+ KB\n"
     ]
    }
   ],
   "source": [
    "# 1. 데이터 선택 및 기본 정제\n",
    "clean_NLP = NLP[['order_id', 'review_comment_message', 'product_category_name']]\n",
    "\n",
    "# 결측치 제거\n",
    "clean_NLP = clean_NLP.dropna(subset=['product_category_name', 'review_comment_message'])\n",
    "\n",
    "# 중복 제거\n",
    "clean_NLP = clean_NLP.drop_duplicates(subset=['review_comment_message']).reset_index(drop=True)\n",
    "\n",
    "clean_NLP.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9066b0e8",
   "metadata": {},
   "source": [
    "# text preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b7a942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           review_comment_message  \\\n",
      "0  O baratheon Ã¨ esxelente Amo adoro o baratheon   \n",
      "1                               Loja responsÃ¡vel   \n",
      "2                       chegou antes do prometido   \n",
      "\n",
      "                 review_comment_message_clean  \n",
      "0  baratheon ã¨ esxelente amo adoro baratheon  \n",
      "1                           loja responsã¡vel  \n",
      "2                      chegou antes prometido  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>review_comment_message</th>\n",
       "      <th>product_category_name</th>\n",
       "      <th>review_comment_message_clean</th>\n",
       "      <th>review_comment_message_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6b7d50bd145f6fc7f33cebabd7e49d0f</td>\n",
       "      <td>O baratheon Ã¨ esxelente Amo adoro o baratheon</td>\n",
       "      <td>casa_conforto</td>\n",
       "      <td>baratheon ã¨ esxelente amo adoro baratheon</td>\n",
       "      <td>[baratheon, ã¨, esxelente, amo, adoro, baratheon]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5741ea1f91b5fbab2bd2dc653a5b5099</td>\n",
       "      <td>Loja responsÃ¡vel</td>\n",
       "      <td>esporte_lazer</td>\n",
       "      <td>loja responsã¡vel</td>\n",
       "      <td>[loja, responsã¡vel]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1ebeea841c590e86a14a0d7a48e7d062</td>\n",
       "      <td>chegou antes do prometido</td>\n",
       "      <td>brinquedos</td>\n",
       "      <td>chegou antes prometido</td>\n",
       "      <td>[chegou, antes, prometido]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7433cbcc783205509d66a5260da5b574</td>\n",
       "      <td>Ã³timo, entregou antes da data prevista.</td>\n",
       "      <td>moveis_decoracao</td>\n",
       "      <td>ã³timo entregou antes data prevista</td>\n",
       "      <td>[ã³timo, entregou, antes, data, prevista]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8428e578bb1cf839ae26a6b7615502b9</td>\n",
       "      <td>Td certo.Produto e prazo de entrega.</td>\n",
       "      <td>automotivo</td>\n",
       "      <td>td certoproduto prazo entrega</td>\n",
       "      <td>[td, certoproduto, prazo, entrega]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>f86c5ed7048ac10eb88ec21c00f71892</td>\n",
       "      <td>Pena o produto nÃ£o ter sido entregue em casa,...</td>\n",
       "      <td>informatica_acessorios</td>\n",
       "      <td>pena produto nã£o ter sido entregue casa q ret...</td>\n",
       "      <td>[pena, produto, nã£o, ter, sido, entregue, cas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>852d2f4d37773bcbc21c8e09a05a4ea5</td>\n",
       "      <td>Produto chegou no prazo o problema que veio na...</td>\n",
       "      <td>telefonia</td>\n",
       "      <td>produto chegou prazo problema veio frente capa...</td>\n",
       "      <td>[produto, chegou, prazo, problema, veio, frent...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>eac76692452422620996fe5e1a7f8bb0</td>\n",
       "      <td>Ameiiii !!! excelente produto...excelente qual...</td>\n",
       "      <td>ferramentas_jardim</td>\n",
       "      <td>ameiiii excelente produtoexcelente qualidade e...</td>\n",
       "      <td>[ameiiii, excelente, produtoexcelente, qualida...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>72bab69c50432c6f94d8b50a5f84b69a</td>\n",
       "      <td>Produto chegou antes da data prevista.</td>\n",
       "      <td>automotivo</td>\n",
       "      <td>produto chegou antes data prevista</td>\n",
       "      <td>[produto, chegou, antes, data, prevista]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>aaff8afa47c8426e414a6d908a97713c</td>\n",
       "      <td>Bom dia eu fiz uma compra de 03 peÃ§as sÃ³ mim...</td>\n",
       "      <td>ferramentas_jardim</td>\n",
       "      <td>bom dia fiz compra 03 peã§as sã³ mim entregaro...</td>\n",
       "      <td>[bom, dia, fiz, compra, 03, peã§as, sã³, mim, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           order_id  \\\n",
       "0  6b7d50bd145f6fc7f33cebabd7e49d0f   \n",
       "1  5741ea1f91b5fbab2bd2dc653a5b5099   \n",
       "2  1ebeea841c590e86a14a0d7a48e7d062   \n",
       "3  7433cbcc783205509d66a5260da5b574   \n",
       "4  8428e578bb1cf839ae26a6b7615502b9   \n",
       "5  f86c5ed7048ac10eb88ec21c00f71892   \n",
       "6  852d2f4d37773bcbc21c8e09a05a4ea5   \n",
       "7  eac76692452422620996fe5e1a7f8bb0   \n",
       "8  72bab69c50432c6f94d8b50a5f84b69a   \n",
       "9  aaff8afa47c8426e414a6d908a97713c   \n",
       "\n",
       "                              review_comment_message   product_category_name  \\\n",
       "0     O baratheon Ã¨ esxelente Amo adoro o baratheon           casa_conforto   \n",
       "1                                  Loja responsÃ¡vel           esporte_lazer   \n",
       "2                          chegou antes do prometido              brinquedos   \n",
       "3           Ã³timo, entregou antes da data prevista.        moveis_decoracao   \n",
       "4               Td certo.Produto e prazo de entrega.              automotivo   \n",
       "5  Pena o produto nÃ£o ter sido entregue em casa,...  informatica_acessorios   \n",
       "6  Produto chegou no prazo o problema que veio na...               telefonia   \n",
       "7  Ameiiii !!! excelente produto...excelente qual...      ferramentas_jardim   \n",
       "8             Produto chegou antes da data prevista.              automotivo   \n",
       "9  Bom dia eu fiz uma compra de 03 peÃ§as sÃ³ mim...      ferramentas_jardim   \n",
       "\n",
       "                        review_comment_message_clean  \\\n",
       "0         baratheon ã¨ esxelente amo adoro baratheon   \n",
       "1                                  loja responsã¡vel   \n",
       "2                             chegou antes prometido   \n",
       "3                ã³timo entregou antes data prevista   \n",
       "4                      td certoproduto prazo entrega   \n",
       "5  pena produto nã£o ter sido entregue casa q ret...   \n",
       "6  produto chegou prazo problema veio frente capa...   \n",
       "7  ameiiii excelente produtoexcelente qualidade e...   \n",
       "8                 produto chegou antes data prevista   \n",
       "9  bom dia fiz compra 03 peã§as sã³ mim entregaro...   \n",
       "\n",
       "                       review_comment_message_tokens  \n",
       "0  [baratheon, ã¨, esxelente, amo, adoro, baratheon]  \n",
       "1                               [loja, responsã¡vel]  \n",
       "2                         [chegou, antes, prometido]  \n",
       "3          [ã³timo, entregou, antes, data, prevista]  \n",
       "4                 [td, certoproduto, prazo, entrega]  \n",
       "5  [pena, produto, nã£o, ter, sido, entregue, cas...  \n",
       "6  [produto, chegou, prazo, problema, veio, frent...  \n",
       "7  [ameiiii, excelente, produtoexcelente, qualida...  \n",
       "8           [produto, chegou, antes, data, prevista]  \n",
       "9  [bom, dia, fiz, compra, 03, peã§as, sã³, mim, ...  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Portuguese stopwords 정의\n",
    "STOP_WORDS = set(stopwords.words('portuguese'))\n",
    "\n",
    "# 2. 텍스트 정제 및 토큰화 함수\n",
    "def clean_and_tokenize(text):\n",
    "    \"\"\"\n",
    "    텍스트를 정제하고 토큰화\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (정제된 텍스트, 토큰 리스트)\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return \"\", []\n",
    "    \n",
    "    # 소문자 변환 및 구두점 제거\n",
    "    cleaned_text = text.lower().translate(str.maketrans('', '', string.punctuation))\n",
    "    \n",
    "    # 토큰화\n",
    "    words = cleaned_text.split()\n",
    "    \n",
    "    # 불용어 제거\n",
    "    filtered_words = [word for word in words if word not in STOP_WORDS]\n",
    "    \n",
    "    return \" \".join(filtered_words), filtered_words\n",
    "\n",
    "# 3. 전처리 적용\n",
    "clean_NLP[['review_comment_message_clean', 'review_comment_message_tokens']] = \\\n",
    "    clean_NLP['review_comment_message'].apply(\n",
    "        lambda text: pd.Series(clean_and_tokenize(text))\n",
    "    )\n",
    "\n",
    "clean_NLP[['review_comment_message', 'review_comment_message_clean']].head(3)\n",
    "clean_NLP.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
